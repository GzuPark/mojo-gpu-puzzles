from gpu.host import DeviceContext
from layout import Layout, LayoutTensor
from layout.tensor_builder import LayoutTensorBuild as tb
from testing import assert_almost_equal

from op import softmax_gpu_kernel, softmax_cpu_kernel

# í™•ë¥  ë¶„í¬ í…ŒìŠ¤íŠ¸ (Probability Distribution Testing)
#
# Softmax í…ŒìŠ¤íŠ¸ì—ì„œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­:
# 1. ëª¨ë“  ì¶œë ¥ê°’ì´ 0 ì´ìƒ (ìŒìˆ˜ í™•ë¥  ì—†ìŒ)
# 2. ëª¨ë“  ì¶œë ¥ê°’ì˜ í•©ì´ 1.0 (ì •ê·œí™” í™•ì¸)
# 3. CPUì™€ GPU ê²°ê³¼ì˜ ì¼ì¹˜ì„± (êµ¬í˜„ ì •í™•ì„±)
# 4. ìˆ˜ì¹˜ì  ì•ˆì •ì„± (í° ì…ë ¥ê°’ì—ì„œë„ ì•ˆì •ì  ë™ì‘)

alias SIZE = 128
alias TPB = 128
alias BLOCKS_PER_GRID = (1, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias layout = Layout.row_major(SIZE)
alias dtype = DType.float32


def test_softmax():
    with DeviceContext() as ctx:
        out = ctx.enqueue_create_buffer[DType.float32](SIZE).enqueue_fill(0)
        inp = ctx.enqueue_create_buffer[DType.float32](SIZE).enqueue_fill(0)

        # for CPU testing
        expected = ctx.enqueue_create_host_buffer[DType.float32](
            SIZE
        ).enqueue_fill(0)
        expected_tensor = LayoutTensor[mut=True, dtype, layout](
            expected.unsafe_ptr()
        )

        # ìˆœì°¨ì  ì¦ê°€ ê°’ìœ¼ë¡œ ì‹¤ì œ ì‹ ê²½ë§ ì¶œë ¥ê³¼ ìœ ì‚¬í•œ íŒ¨í„´ ìƒì„±
        #
        # ì™œ ìˆœì°¨ì  ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?
        # 1. ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²°ê³¼ë¡œ ë””ë²„ê¹… ìš©ì´
        # 2. í° ê°’ì—ì„œ ì‘ì€ ê°’ê¹Œì§€ ë‹¤ì–‘í•œ ë²”ìœ„ í…ŒìŠ¤íŠ¸
        # 3. Softmaxì˜ ìˆ˜ì¹˜ì  ì•ˆì •ì„± í™•ì¸ (í° ê°’ë“¤ì´ í¬í•¨ë¨)
        # Initialize input with more reasonable values
        with inp.map_to_host() as inp_host:
            for i in range(SIZE):
                inp_host[i] = Float32(i)

            print("Input values:")
            for i in range(SIZE):
                print(inp_host[i], end=" ")
            print()
            # Create layout tensors for CPU calculation
            input_host_tensor = LayoutTensor[mut=True, dtype, layout](
                inp_host.unsafe_ptr()
            )

        # for GPU testing
        output_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())
        input_tensor = LayoutTensor[mut=True, dtype, layout](inp.unsafe_ptr())

        # CPUë¥¼ ê¸°ì¤€ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²€ì¦ íŒ¨í„´
        # 1. CPU êµ¬í˜„ì´ ë” ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ì›Œì„œ ë²„ê·¸ ê°€ëŠ¥ì„±ì´ ë‚®ìŒ
        # 2. GPU ë³‘ë ¬ ì²˜ë¦¬ì˜ ë³µì¡ì„±ì„ ìˆœì°¨ ì²˜ë¦¬ë¡œ ê²€ì¦ ê°€ëŠ¥
        # 3. ë™ì¼í•œ ì•Œê³ ë¦¬ì¦˜ì˜ ì„œë¡œ ë‹¤ë¥¸ êµ¬í˜„ ê°„ ì¼ì¹˜ì„± í™•ì¸
        # Compute expected results using our CPU kernel
        softmax_cpu_kernel[layout, SIZE, dtype](
            expected_tensor, input_host_tensor
        )

        # Run GPU kernel
        ctx.enqueue_function[softmax_gpu_kernel[layout, SIZE, dtype]](
            output_tensor,
            input_tensor,
            grid_dim=BLOCKS_PER_GRID,
            block_dim=THREADS_PER_BLOCK,
        )

        ctx.synchronize()

        with out.map_to_host() as out_host:
            print("GPU softmax results:")
            for i in range(SIZE):
                print(out_host[i], end=" ")
            print()

            print("Expected results:")
            for i in range(SIZE):
                print(expected[i], end=" ")
            print()

            # í™•ë¥  ë¶„í¬ ìœ íš¨ì„± ê²€ì¦
            # 1. ê°œë³„ ê°’ì˜ ì •í™•ì„± (assert_almost_equal)
            # 2. ì „ì²´ í™•ë¥ ì˜ í•©ì´ 1.0ì¸ì§€ í™•ì¸
            # 3. ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ í—ˆìš© (atol, rtol ì„¤ì •)
            var sum_gpu: Float32 = 0.0
            for i in range(SIZE):
                sum_gpu += out_host[i]
                assert_almost_equal(
                    out_host[i], expected[i], atol=1e-5, rtol=1e-5
                )

            print("Sum of probabilities:", sum_gpu)

            # í™•ë¥  ë¶„í¬ ì •ê·œí™” ê²€ì¦
            # - Softmax êµ¬í˜„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ëŠ” í•µì‹¬ í…ŒìŠ¤íŠ¸
            assert_almost_equal(sum_gpu, 1.0, atol=1e-5, rtol=1e-5)
            print("All tests passed ğŸ‰")

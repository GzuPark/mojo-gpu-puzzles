# ANCHOR: softmax_custom_op_graph
from pathlib import Path
from time import perf_counter
import numpy as np
from max.driver import CPU, Accelerator, Device, Tensor
from max.dtype import DType
from max.engine import InferenceSession
from max.graph import DeviceRef, Graph, TensorType, ops
from numpy.typing import NDArray
from scipy.special import softmax as scipy_softmax

# Batched Softmax ì—°ì‚°ì„ ìœ„í•œ MAX Graph í†µí•©
# Row-wise vs Column-wise í™•ë¥  ë¶„í¬ ì •ê·œí™”
#
# Batched Softmax í•¨ìˆ˜ì˜ íŠ¹ì§•:
# 1. 2D ì…ë ¥ í…ì„œ (BATCH_SIZE, FEATURE_SIZE)
# 2. Row-wise: ê° í–‰(row)ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ softmax ì ìš©
# 3. Column-wise: ê° ì—´(column)ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ softmax ì ìš©
# 4. ì„±ëŠ¥ ë¹„êµ: ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ê³¼ ë³‘ë ¬ì„±ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„

def compile_softmax_model(
    input_shape: tuple,
    session: InferenceSession,
    device: Device,
    mode: str = "row_wise",  # "row_wise" ë˜ëŠ” "col_wise"
):
    """Softmax ëª¨ë¸ì„ ì»´íŒŒì¼í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤. (í•œ ë²ˆë§Œ ì»´íŒŒì¼)"""
    dtype = DType.float32
    mojo_kernels = Path(__file__).parent / "op"

    with Graph(
        f"softmax_graph_{mode}",
        input_types=[
            TensorType(
                dtype,
                shape=input_shape,
                device=DeviceRef.from_device(device),
            ),
        ],
        custom_extensions=[mojo_kernels],
    ) as graph:
        input_value = graph.inputs[0]

        # Batched SoftmaxëŠ” ì…ë ¥ê³¼ ë™ì¼í•œ í¬ê¸°ì˜ ì¶œë ¥ ìƒì„±
        output = ops.custom(
            name="softmax",
            values=[input_value],
            device=DeviceRef.from_device(device),
            out_types=[
                TensorType(
                    dtype=input_value.tensor.dtype,
                    shape=input_value.tensor.shape,
                    device=DeviceRef.from_device(device),
                )
            ],
            parameters={
                "batch_size": input_shape[0],  # ë°°ì¹˜ í¬ê¸° (í–‰ ê°œìˆ˜)
                "feature_size": input_shape[1],  # íŠ¹ì„± í¬ê¸° (ì—´ ê°œìˆ˜)
                "mode": mode,  # "row_wise" ë˜ëŠ” "col_wise"
                "dtype": dtype,
                "target": "gpu" if device == Accelerator() else "cpu",
            },
        )[0].tensor
        graph.output(output)

    print(f"ğŸ“¦ {mode} softmax ëª¨ë¸ì„ {device}ì—ì„œ ì»´íŒŒì¼ ì¤‘...")
    compiled_model = session.load(graph)
    print(f"âœ… {mode} ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ")
    return compiled_model


def execute_softmax_model(
    compiled_model,
    input_array: NDArray[np.float32],
    device: Device,
) -> Tensor:
    """ì»´íŒŒì¼ëœ ëª¨ë¸ë¡œ softmaxë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    input_tensor = Tensor.from_numpy(input_array).to(device)
    result = compiled_model.execute(input_tensor)[0]
    assert isinstance(result, Tensor)
    return result.to(CPU()) if device == Accelerator() else result


def benchmark_softmax_optimized(
    input_array: NDArray[np.float32],
    session: InferenceSession,
    device: Device,
    warmup_runs: int = 5,
    benchmark_runs: int = 20
) -> dict:
    """ì»´íŒŒì¼ê³¼ ì‹¤í–‰ì„ ë¶„ë¦¬í•œ ìµœì í™”ëœ ë²¤ì¹˜ë§ˆí¬"""

    results = {}
    compiled_models = {}

    print(f"ğŸ”§ ì»´íŒŒì¼ ë‹¨ê³„")
    print(f"{'='*50}")

    # 1ë‹¨ê³„: ëª¨ë“  ëª¨ë“œì— ëŒ€í•´ ì‚¬ì „ ì»´íŒŒì¼
    for mode in ["row_wise", "col_wise"]:
        compiled_models[mode] = compile_softmax_model(
            input_array.shape, session, device, mode
        )

    print(f"\nğŸš€ ì‹¤í–‰ ë‹¨ê³„")
    print(f"{'='*50}")

    # 2ë‹¨ê³„: ì»´íŒŒì¼ëœ ëª¨ë¸ë¡œ ìˆœìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
    for mode in ["row_wise", "col_wise"]:
        mode_kr = "í–‰ë³„" if mode == "row_wise" else "ì—´ë³„"
        print(f"\n=== {mode_kr.upper()} SOFTMAX ë²¤ì¹˜ë§ˆí¬ ===")

        compiled_model = compiled_models[mode]

        # Warmup ì‹¤í–‰ (GPU ë©”ëª¨ë¦¬ ìµœì í™”)
        print(f"ğŸ”¥ {mode_kr} ì‹¤í–‰ ì›Œë°ì—… ì¤‘...")
        for i in range(warmup_runs):
            _ = execute_softmax_model(compiled_model, input_array, device)
            if i % 2 == 0:
                print(f"  ì›Œë°ì—… {i+1}/{warmup_runs}")

        # ìˆœìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • (ì»´íŒŒì¼ ì œì™¸)
        print(f"â±ï¸  ìˆœìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ì¤‘...")
        times = []
        for i in range(benchmark_runs):
            start_time = perf_counter()
            result = execute_softmax_model(compiled_model, input_array, device)
            end_time = perf_counter()

            execution_time = (end_time - start_time) * 1000  # ms ë‹¨ìœ„
            times.append(execution_time)

            if i % 5 == 0 or i == benchmark_runs - 1:
                print(f"  ì‹¤í–‰ {i+1}/{benchmark_runs}: {execution_time:.3f} ms")

        # í†µê³„ ê³„ì‚°
        avg_time = np.mean(times)
        min_time = np.min(times)
        max_time = np.max(times)
        std_time = np.std(times)
        median_time = np.median(times)

        results[mode] = {
            "times": times,
            "avg_time": avg_time,
            "min_time": min_time,
            "max_time": max_time,
            "std_time": std_time,
            "median_time": median_time,
            "result": result
        }

        print(f"ğŸ“Š ê²°ê³¼:")
        print(f"  í‰ê· :   {avg_time:.3f} ms")
        print(f"  ì¤‘ê°„ê°’: {median_time:.3f} ms")
        print(f"  ìµœì†Œ:   {min_time:.3f} ms")
        print(f"  ìµœëŒ€:   {max_time:.3f} ms")
        print(f"  í‘œì¤€í¸ì°¨: {std_time:.3f} ms")

    return results


def verify_correctness(results: dict, input_array: NDArray[np.float32]):
    """ë‘ ë°©ì‹ì˜ ê²°ê³¼ê°€ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•©ë‹ˆë‹¤."""

    print(f"\n=== ì •í™•ì„± ê²€ì¦ ===")

    row_result = results["row_wise"]["result"].to_numpy()
    col_result = results["col_wise"]["result"].to_numpy()

    # ê²°ê³¼ shape ë° ê¸°ë³¸ ì •ë³´ ì¶œë ¥
    print(f"ğŸ“ ê²°ê³¼ í˜•íƒœ ì •ë³´:")
    print(f"  ì…ë ¥ í˜•íƒœ: {input_array.shape}")
    print(f"  í–‰ë³„ ì¶œë ¥ í˜•íƒœ: {row_result.shape}")
    print(f"  ì—´ë³„ ì¶œë ¥ í˜•íƒœ: {col_result.shape}")
    print(f"  ê²°ê³¼ë‹¹ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {row_result.nbytes / 1024:.1f} KB")

    # ì²« ëª‡ ê°œ ê°’ ì¶œë ¥
    print(f"\nğŸ” ìƒ˜í”Œ ê²°ê³¼ (ì²« ë²ˆì§¸ í–‰):")
    print(f"  ì…ë ¥ê°’: {input_array[0][:5]}")
    print(f"  í–‰ë³„ softmax: {row_result[0][:5]}")
    print(f"  ì—´ë³„ softmax: {col_result[0][:5]}")

    # Row-wise: SciPyì™€ ë¹„êµ (ê° í–‰ë³„ softmax)
    expected_row = np.array([scipy_softmax(row) for row in input_array])
    np.testing.assert_allclose(row_result, expected_row, rtol=1e-5)
    print(f"\nâœ… í–‰ë³„ ê²°ê³¼ê°€ SciPy ê³„ì‚°ê³¼ ì¼ì¹˜í•¨")

    # Column-wise: SciPyì™€ ë¹„êµ (ê° ì—´ë³„ softmax)
    expected_col = np.array([scipy_softmax(col) for col in input_array.T]).T
    np.testing.assert_allclose(col_result, expected_col, rtol=1e-5)
    print("âœ… ì—´ë³„ ê²°ê³¼ê°€ SciPy ê³„ì‚°ê³¼ ì¼ì¹˜í•¨")

    # í™•ë¥  ë¶„í¬ ì†ì„± ê²€ì¦
    row_sums = np.sum(row_result, axis=1)  # ê° í–‰ì˜ í•©
    col_sums = np.sum(col_result, axis=0)  # ê° ì—´ì˜ í•©

    assert np.allclose(row_sums, 1.0, atol=1e-6), f"í–‰ë³„ í•©ì´ 1.0ì´ ì•„ë‹˜: {row_sums}"
    assert np.allclose(col_sums, 1.0, atol=1e-6), f"ì—´ë³„ í•©ì´ 1.0ì´ ì•„ë‹˜: {col_sums}"

    print(f"âœ… í–‰ë³„ í™•ë¥  í•©ê³„: {np.round(row_sums[:5], 5)}")
    print(f"âœ… ì—´ë³„ í™•ë¥  í•©ê³„: {np.round(col_sums[:5], 5)}")


def analyze_performance_detailed(results: dict):
    """ìƒì„¸í•œ ì„±ëŠ¥ ë¶„ì„ ë° ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ ë¹„êµ"""

    print(f"\n=== ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ===")

    row_stats = results["row_wise"]
    col_stats = results["col_wise"]

    row_avg = row_stats["avg_time"]
    col_avg = col_stats["avg_time"]
    row_min = row_stats["min_time"]
    col_min = col_stats["min_time"]
    row_median = row_stats["median_time"]
    col_median = col_stats["median_time"]

    print(f"\nğŸ“ˆ ì‹¤í–‰ ì‹œê°„ ë¹„êµ:")
    print(f"â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"â”‚ ì§€í‘œ        â”‚ í–‰ë³„         â”‚ ì—´ë³„         â”‚ ì°¨ì´         â”‚")
    print(f"â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚ í‰ê·         â”‚ {row_avg:8.3f} ms  â”‚ {col_avg:8.3f} ms  â”‚ {abs(row_avg-col_avg):8.3f} ms  â”‚")
    print(f"â”‚ ì¤‘ê°„ê°’      â”‚ {row_median:8.3f} ms  â”‚ {col_median:8.3f} ms  â”‚ {abs(row_median-col_median):8.3f} ms  â”‚")
    print(f"â”‚ ìµœê³ (ìµœì†Œ)  â”‚ {row_min:8.3f} ms  â”‚ {col_min:8.3f} ms  â”‚ {abs(row_min-col_min):8.3f} ms  â”‚")
    print(f"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    if row_avg < col_avg:
        speedup = col_avg / row_avg
        winner = "í–‰ë³„"
        print(f"\nğŸ† {winner} ë°©ì‹ì´ {speedup:.2f}x ë¹ ë¦„!")
    else:
        speedup = row_avg / col_avg
        winner = "ì—´ë³„"
        print(f"\nğŸ† {winner} ë°©ì‹ì´ {speedup:.2f}x ë¹ ë¦„!")

    print(f"\nğŸ§  ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ ë¶„ì„:")
    print(f"")
    print(f"í–‰ë³„ (ìˆœì°¨ ì ‘ê·¼ íŒ¨í„´):")
    print(f"  ğŸŸ¢ ìºì‹œ ì§€ì—­ì„±: ìš°ìˆ˜ (ì—°ì† ë©”ëª¨ë¦¬ ì ‘ê·¼)")
    print(f"  ğŸŸ¢ ë©”ëª¨ë¦¬ ëŒ€ì—­í­: ë†’ì€ í™œìš©ë¥  (~80-90%)")
    print(f"  ğŸŸ¢ DRAM ë²„ìŠ¤íŠ¸ íš¨ìœ¨ì„±: ìµœì  (128ë°”ì´íŠ¸ ìºì‹œ ë¼ì¸)")
    print(f"  ğŸ”´ ë³‘ë ¬ì„±: ë°°ì¹˜ ì°¨ì›ì— ì˜í•´ ì œí•œë¨")
    print(f"  ğŸ“Š ìµœì í™” ëŒ€ìƒ: í° íŠ¹ì„± í¬ê¸°, ì‘ì€ ë°°ì¹˜ í¬ê¸°")

    print(f"")
    print(f"ì—´ë³„ (ìŠ¤íŠ¸ë¼ì´ë“œ ì ‘ê·¼ íŒ¨í„´):")
    print(f"  ğŸ”´ ìºì‹œ ì§€ì—­ì„±: ë¶ˆëŸ‰ (ìŠ¤íŠ¸ë¼ì´ë“œ ë©”ëª¨ë¦¬ ì ‘ê·¼)")
    print(f"  ğŸ”´ ë©”ëª¨ë¦¬ ëŒ€ì—­í­: ë‚®ì€ í™œìš©ë¥  (~30-50%)")
    print(f"  ğŸ”´ DRAM ë²„ìŠ¤íŠ¸ íš¨ìœ¨ì„±: ë¹„ìµœì  (ë§ì€ ìºì‹œ ë¯¸ìŠ¤)")
    print(f"  ğŸŸ¢ ë³‘ë ¬ì„±: íŠ¹ì„± ì°¨ì›ì—ì„œ ìµœëŒ€")
    print(f"  ğŸ“Š ìµœì í™” ëŒ€ìƒ: ì‘ì€ íŠ¹ì„± í¬ê¸°, í° ë°°ì¹˜ í¬ê¸°")

    # ì„±ëŠ¥ ë³€ë™ì„± ë¶„ì„
    row_cv = (row_stats["std_time"] / row_stats["avg_time"]) * 100
    col_cv = (col_stats["std_time"] / col_stats["avg_time"]) * 100

    print(f"\nğŸ“Š ì„±ëŠ¥ ì•ˆì •ì„±:")
    print(f"í–‰ë³„ ë³€ë™ê³„ìˆ˜: {row_cv:.2f}%")
    print(f"ì—´ë³„ ë³€ë™ê³„ìˆ˜: {col_cv:.2f}%")

    if row_cv < col_cv:
        print(f"âœ… í–‰ë³„ì´ ë” ì¼ê´€ëœ ì„±ëŠ¥ì„ ë³´ì„")
    else:
        print(f"âœ… ì—´ë³„ì´ ë” ì¼ê´€ëœ ì„±ëŠ¥ì„ ë³´ì„")


if __name__ == "__main__":
    # 2D Batched Softmax í…ŒìŠ¤íŠ¸ ì„¤ì •
    BATCH_SIZE = 8      # ë°°ì¹˜ í¬ê¸° ì¦ê°€ (ë” í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸)
    FEATURE_SIZE = 512  # íŠ¹ì„± í¬ê¸° ì¦ê°€ (ë©”ëª¨ë¦¬ íŒ¨í„´ ì°¨ì´ ê·¹ëŒ€í™”)

    cpu_session = InferenceSession(devices=[CPU()])
    gpu_session = InferenceSession(devices=[Accelerator()])

    # 2D ì…ë ¥ ë°°ì—´ ìƒì„± (BATCH_SIZE, FEATURE_SIZE)
    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •
    input_array = np.random.randn(BATCH_SIZE, FEATURE_SIZE).astype(np.float32)

    print(f"ğŸ¯ ì¢…í•© Batched Softmax ë²¤ì¹˜ë§ˆí¬")
    print(f"{'='*80}")
    print(f"ì…ë ¥ í˜•íƒœ: {input_array.shape}")
    print(f"ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}, íŠ¹ì„± í¬ê¸°: {FEATURE_SIZE}")
    print(f"ì´ ì›ì†Œ ìˆ˜: {BATCH_SIZE * FEATURE_SIZE:,}ê°œ")
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {input_array.nbytes / 1024:.1f} KB")
    print(f"ë°ì´í„° íƒ€ì…: {input_array.dtype}")
    print(f"ì²« ë²ˆì§¸ í–‰ ì…ë ¥ê°’ ìƒ˜í”Œ: {input_array[0][:5]}")

    # CPU ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    print(f"\nğŸ’» CPU ë²¤ì¹˜ë§ˆí¬")
    print(f"{'='*50}")
    cpu_results = benchmark_softmax_optimized(
        input_array, cpu_session, CPU(),
        warmup_runs=3, benchmark_runs=20  # CPUëŠ” GPUë³´ë‹¤ ì ì€ ì‹¤í–‰
    )

    # GPU ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (ì»´íŒŒì¼ ë¶„ë¦¬)
    print(f"\nğŸ”¥ GPU ë²¤ì¹˜ë§ˆí¬")
    print(f"{'='*50}")
    gpu_results = benchmark_softmax_optimized(
        input_array, gpu_session, Accelerator(),
        warmup_runs=5, benchmark_runs=50  # ë” ì •í™•í•œ ì¸¡ì •ì„ ìœ„í•´ ì‹¤í–‰ íšŸìˆ˜ ì¦ê°€
    )

    verify_correctness(gpu_results, input_array)
    analyze_performance_detailed(gpu_results)

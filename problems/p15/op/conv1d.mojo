from gpu import thread_idx, block_idx, block_dim, barrier
from gpu.host import DeviceContext
from layout import Layout, LayoutTensor
from layout.tensor_builder import LayoutTensorBuild as tb

# Custom Operation Package
#
# ì´ì „ í¼ì¦ê³¼ì˜ ì°¨ì´ì :
# - ì´ì „: ìˆœìˆ˜ Mojo í™˜ê²½ì—ì„œ GPU ì»¤ë„ ì‘ì„± ë° ì‹¤í–‰
# - í˜„ì¬: Pythonì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ Mojo íŒ¨í‚¤ì§€ ìƒì„±
# - ì´ì „: main() í•¨ìˆ˜ì—ì„œ ì§ì ‘ ì»¤ë„ í…ŒìŠ¤íŠ¸
# - í˜„ì¬: @compiler.register ë°ì½”ë ˆì´í„°ë¡œ ì—°ì‚° ë“±ë¡
#
# ğŸ“¦ íŒ¨í‚¤ì§€ êµ¬ì¡°ì˜ ì´í•´:
# problems/p15/op/
# â”œâ”€â”€ __init__.mojo          # íŒ¨í‚¤ì§€ ì´ˆê¸°í™” íŒŒì¼
# â””â”€â”€ conv1d.mojo           # ì´ íŒŒì¼ - ì‚¬ìš©ì ì •ì˜ ì—°ì‚° êµ¬í˜„
#
# ì´ êµ¬ì¡°ëŠ” Pythonì˜ íŒ¨í‚¤ì§€ ì‹œìŠ¤í…œê³¼ ìœ ì‚¬í•˜ë©°,
# MAX Graphì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œí•  ìˆ˜ ìˆëŠ” Mojo ëª¨ë“ˆì„ ì œê³µí•©ë‹ˆë‹¤.

# ANCHOR: conv1d_kernel
alias TPB = 15
alias BLOCKS_PER_GRID = (2, 1)


# ê¸°ì¡´ GPU ì»¤ë„ ì¬ì‚¬ìš©
# ì´ ì»¤ë„ì€ Puzzle 11ì—ì„œ í•™ìŠµí•œ ê²ƒê³¼ ë™ì¼í•œ ë¡œì§ì…ë‹ˆë‹¤.
# ìƒˆë¡œìš´ ì ì€ ì´ì œ ì´ ì»¤ë„ì´ Pythonì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ íŒ¨í‚¤ì§€ì˜ ì¼ë¶€ë¼ëŠ” ê²ƒì…ë‹ˆë‹¤.
#
# ì»¤ë„ ê¸°ëŠ¥ ìš”ì•½ (Puzzle 11ì—ì„œ í•™ìŠµí•œ ë‚´ìš©):
# - 1D ì»¨ë³¼ë£¨ì…˜ ì—°ì‚° ìˆ˜í–‰
# - ê³µìœ  ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•œ ì„±ëŠ¥ ìµœì í™”
# - ë¸”ë¡ ê²½ê³„ ë°ì´í„° ì²˜ë¦¬
# - ì œë¡œ íŒ¨ë”©ì„ í†µí•œ ê²½ê³„ ì¡°ê±´ ì²˜ë¦¬
fn conv1d_kernel[
    in_layout: Layout,
    out_layout: Layout,
    conv_layout: Layout,
    input_size: Int,
    conv_size: Int,
    dtype: DType = DType.float32,
](
    output: LayoutTensor[mut=True, dtype, out_layout],
    input: LayoutTensor[mut=True, dtype, in_layout],
    kernel: LayoutTensor[mut=True, dtype, conv_layout],
):
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    # first: need to account for padding
    shared_a = tb[dtype]().row_major[TPB + conv_size - 1]().shared().alloc()
    shared_b = tb[dtype]().row_major[conv_size]().shared().alloc()
    if global_i < input_size:
        shared_a[local_i] = input[global_i]

    # second: load elements needed for convolution at block boundary
    if local_i < conv_size - 1:
        # indices from next block
        next_idx = global_i + TPB
        if next_idx < input_size:
            shared_a[TPB + local_i] = input[next_idx]

    if local_i < conv_size:
        shared_b[local_i] = kernel[local_i]

    barrier()

    if global_i < input_size:
        var local_sum: output.element_type = 0

        @parameter
        for j in range(conv_size):
            if local_i + j < TPB + conv_size - 1:
                local_sum += shared_a[local_i + j] * shared_b[j]

        output[global_i] = local_sum


# ANCHOR_END: conv1d_kernel


# ANCHOR: conv1d_custom_op
import compiler  # @compiler.register ë°ì½”ë ˆì´í„° ì œê³µ
from runtime.asyncrt import DeviceContextPtr  # ë¹„ë™ê¸° ëŸ°íƒ€ì„ ì»¨í…ìŠ¤íŠ¸
from tensor import InputTensor, OutputTensor  # MAX Graph í…ì„œ ì¸í„°í˜ì´ìŠ¤
from memory import UnsafePointer
from gpu.host import DeviceBuffer  # GPU ë©”ëª¨ë¦¬ ë²„í¼ ê´€ë¦¬


# ì‚¬ìš©ì ì •ì˜ ì—°ì‚° ë“±ë¡ (@compiler.register)
#
# @compiler.register ë°ì½”ë ˆì´í„°ì˜ ì—­í• :
# 1. Mojo í•¨ìˆ˜ë¥¼ MAX Graphì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ì—°ì‚°ìœ¼ë¡œ ë“±ë¡
# 2. Pythonì˜ ops.custom(name="conv1d", ...)ì—ì„œ ì´ ì´ë¦„ìœ¼ë¡œ í˜¸ì¶œ
# 3. ì»´íŒŒì¼ íƒ€ì„ì— ì—°ì‚° ë©”íƒ€ë°ì´í„° ìƒì„±
# 4. ëŸ°íƒ€ì„ì— ë™ì  ë””ìŠ¤íŒ¨ì¹˜ ê°€ëŠ¥
#
# ì´ëŠ” PyTorchì˜ custom C++ ì—°ì‚°ì´ë‚˜ TensorFlowì˜ custom opì™€ ìœ ì‚¬í•œ ê°œë…ì…ë‹ˆë‹¤.
@compiler.register("conv1d")
struct Conv1DCustomOp:
    # ì •ì  ë©”ì„œë“œë¥¼ í†µí•œ ì—°ì‚° ì¸í„°í˜ì´ìŠ¤
    # ì´ì „: ì¼ë°˜ í•¨ìˆ˜ë¡œ GPU ì»¤ë„ ì •ì˜
    # í˜„ì¬: struct ë‚´ì˜ ì •ì  ë©”ì„œë“œë¡œ MAX Graph ì¸í„°í˜ì´ìŠ¤ ì œê³µ
    #
    # ì™œ structì™€ ì •ì  ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?
    # 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê²©ë¦¬ (Conv1DCustomOp.execute)
    # 2. ë©”íƒ€ë°ì´í„° ì²¨ë¶€ ê°€ëŠ¥ (@compiler.registerì™€ ì—°ê²°)
    # 3. íƒ€ì… ì•ˆì „ì„± í–¥ìƒ
    # 4. ì—¬ëŸ¬ ì—°ì‚°ì„ í•˜ë‚˜ì˜ íŒ¨í‚¤ì§€ì— í¬í•¨ ê°€ëŠ¥
    @staticmethod
    fn execute[
        # ì»´íŒŒì¼ íƒ€ì„ ë§¤ê°œë³€ìˆ˜
        # ì´ì „: ëŸ°íƒ€ì„ì— ê°’ ì „ë‹¬
        # í˜„ì¬: ì»´íŒŒì¼ íƒ€ì„ì— ìµœì í™”ë¥¼ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ì „ë‹¬
        #
        # target: "cpu" ë˜ëŠ” "gpu" - ì‹¤í–‰ ëŒ€ìƒ ë””ë°”ì´ìŠ¤
        # input_size, conv_size: Pythonì—ì„œ ì „ë‹¬ëœ í¬ê¸° ì •ë³´
        # dtype: ë°ì´í„° íƒ€ì… (ì»´íŒŒì¼ íƒ€ì„ ìµœì í™”ìš©)
        target: StaticString,  # ì»´íŒŒì¼ íƒ€ì„ ë¬¸ìì—´ ìƒìˆ˜
        input_size: Int,
        conv_size: Int,
        dtype: DType = DType.float32,
    ](
        # MAX Graph í…ì„œ ì¸í„°í˜ì´ìŠ¤
        # ì´ì „: LayoutTensor ì§ì ‘ ì‚¬ìš©
        # í˜„ì¬: InputTensor/OutputTensor ì¶”ìƒí™” ë ˆì´ì–´
        #
        # InputTensor/OutputTensorì˜ ì¥ì :
        # 1. Python-Mojo ê°„ íƒ€ì… ì•ˆì „ì„±
        # 2. ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬
        # 3. ë””ë°”ì´ìŠ¤ ê°„ íˆ¬ëª…í•œ ë°ì´í„° ì´ë™
        # 4. MAX Graph ìµœì í™” ì—”ì§„ê³¼ í†µí•©
        output: OutputTensor[rank=1],  # 1ì°¨ì› ì¶œë ¥ í…ì„œ
        input: InputTensor[rank=1],  # ì…ë ¥ í…ì„œ (1ì°¨ì›)
        kernel: InputTensor[rank=1],  # ì»¤ë„ í…ì„œ (1ì°¨ì›)
        # Device Context Pointer
        # ì´ì „: DeviceContextë¥¼ ì§ì ‘ ìƒì„±í•˜ì—¬ ì‚¬ìš©
        # í˜„ì¬: MAX Graphì—ì„œ ê´€ë¦¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬ì¸í„°ë¡œ ì „ë‹¬ë°›ìŒ
        #
        # DeviceContextPtrì˜ ì—­í• :
        # 1. GPU ë©”ëª¨ë¦¬ í• ë‹¹/í•´ì œ ê´€ë¦¬
        # 2. ì»¤ë„ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ë§
        # 3. ë””ë°”ì´ìŠ¤ ê°„ ë°ì´í„° ë™ê¸°í™”
        # 4. ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
        ctx: DeviceContextPtr,
    ) raises:
        # MAX Graph í…ì„œ â†’ LayoutTensor ë³€í™˜
        # ì´ì „: ì§ì ‘ LayoutTensor ì‚¬ìš©
        # í˜„ì¬: MAX Graph í…ì„œë¥¼ LayoutTensorë¡œ ë³€í™˜í•˜ì—¬ ê¸°ì¡´ ì»¤ë„ ì¬ì‚¬ìš©
        #
        # .to_layout_tensor()ì˜ ì—­í• :
        # 1. MAX Graphì˜ ì¶”ìƒí™”ëœ í…ì„œë¥¼ Mojo ë„¤ì´í‹°ë¸Œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        # 2. ë©”ëª¨ë¦¬ ë ˆì´ì•„ì›ƒ ì •ë³´ ì¶”ì¶œ
        # 3. GPU í¬ì¸í„° ì ‘ê·¼ í—ˆìš©
        # 4. ê¸°ì¡´ GPU ì»¤ë„ê³¼ì˜ í˜¸í™˜ì„± ì œê³µ
        output_tensor = output.to_layout_tensor()
        input_tensor = input.to_layout_tensor()
        kernel_tensor = kernel.to_layout_tensor()

        # ì»´íŒŒì¼ íƒ€ì„ ë ˆì´ì•„ì›ƒ ì¶”ì¶œ
        # ì´ì „: í•¨ìˆ˜ ë§¤ê°œë³€ìˆ˜ë¡œ ë ˆì´ì•„ì›ƒ ì „ë‹¬
        # í˜„ì¬: ëŸ°íƒ€ì„ í…ì„œì—ì„œ ì»´íŒŒì¼ íƒ€ì„ ë ˆì´ì•„ì›ƒ ì •ë³´ ì¶”ì¶œ
        #
        # aliasë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ :
        # 1. ì»´íŒŒì¼ íƒ€ì„ ìƒìˆ˜ë¡œ ì²˜ë¦¬ (ì„±ëŠ¥ ìµœì í™”)
        # 2. íƒ€ì… ê²€ì¦ ê°•í™”
        # 3. GPU ì»¤ë„ì˜ ë§¤ê°œë³€ìˆ˜ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±
        alias in_layout = input_tensor.layout
        alias output_layout = output_tensor.layout
        alias conv_layout = kernel_tensor.layout

        # ì¡°ê±´ë¶€ ì»´íŒŒì¼ (@parameter if)
        # ì´ì „: ëŸ°íƒ€ì„ ì¡°ê±´ë¬¸ ì‚¬ìš©
        # í˜„ì¬: ì»´íŒŒì¼ íƒ€ì„ ì¡°ê±´ë¬¸ìœ¼ë¡œ ë””ë°”ì´ìŠ¤ë³„ ìµœì í™”
        #
        # @parameter ifì˜ ì¥ì :
        # 1. ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì½”ë“œ ê²½ë¡œ ì œê±° (ì½”ë“œ í¬ê¸° ê°ì†Œ)
        # 2. ë””ë°”ì´ìŠ¤ë³„ íŠ¹í™” ìµœì í™” ê°€ëŠ¥
        # 3. íƒ€ì… ê²€ì¦ ê°•í™”
        # 4. ì‹¤í–‰ ì‹œ ë¶„ê¸° ì˜¤ë²„í—¤ë“œ ì œê±°
        @parameter
        if target == "gpu":
            # ë””ë°”ì´ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë©”ëª¨ë¦¬ ê´€ë¦¬
            # ì´ì „: with DeviceContext() as ctx: íŒ¨í„´ ì‚¬ìš©
            # í˜„ì¬: MAX Graphì—ì„œ ì „ë‹¬ë°›ì€ ì»¨í…ìŠ¤íŠ¸ í¬ì¸í„° í™œìš©
            #
            # ctx.get_device_context()ì˜ ì—­í• :
            # 1. í¬ì¸í„°ì—ì„œ ì‹¤ì œ DeviceContext ê°ì²´ ì¶”ì¶œ
            # 2. GPU ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œ íšë“
            # 3. ë©”ëª¨ë¦¬ í’€ ë° ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬ í™œì„±í™”
            gpu_ctx = ctx.get_device_context()

            # ëª…ì‹œì  ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
            # ì´ì „: .enqueue_fill(0)ìœ¼ë¡œ ë²„í¼ ì´ˆê¸°í™”
            # í˜„ì¬: enqueue_memsetìœ¼ë¡œ ì €ìˆ˜ì¤€ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
            #
            # ì™œ ëª…ì‹œì  ì´ˆê¸°í™”ê°€ í•„ìš”í•œê°€?
            # 1. MAX Graphì—ì„œ ì „ë‹¬ë°›ì€ ì¶œë ¥ ë²„í¼ëŠ” ì´ˆê¸°í™”ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
            # 2. ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì—ì„œ ëˆ„ì  í•©ê³„ë¥¼ ì˜¬ë°”ë¥´ê²Œ ê³„ì‚°í•˜ê¸° ìœ„í•´ í•„ìš”
            # 3. ë©”ëª¨ë¦¬ ì•ˆì „ì„± ë³´ì¥
            # 4. ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ ë³´ì¥
            gpu_ctx.enqueue_memset(
                # DeviceBufferë¥¼ í†µí•œ ì•ˆì „í•œ ë©”ëª¨ë¦¬ ì ‘ê·¼
                # ì´ì „: unsafe_ptr() ì§ì ‘ ì‚¬ìš©
                # í˜„ì¬: DeviceBufferë¡œ ë˜í•‘í•˜ì—¬ íƒ€ì… ì•ˆì „ì„± ì œê³µ
                #
                # DeviceBuffer êµ¬ì„± ìš”ì†Œ:
                # - output.dtype: ë²„í¼ì˜ ë°ì´í„° íƒ€ì…
                # - gpu_ctx: ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•˜ëŠ” ë””ë°”ì´ìŠ¤ ì»¨í…ìŠ¤íŠ¸
                # - rebind[...]: í¬ì¸í„° íƒ€ì… ë³€í™˜ (íƒ€ì… ì•ˆì „ì„± ìœ ì§€)
                # - input_size: ë²„í¼ í¬ê¸° (ìš”ì†Œ ê°œìˆ˜)
                # - owning=False: ë©”ëª¨ë¦¬ ì†Œìœ ê¶Œì„ ê°–ì§€ ì•ŠìŒ (MAX Graphê°€ ê´€ë¦¬)
                DeviceBuffer[dtype](
                    gpu_ctx,
                    rebind[UnsafePointer[Scalar[dtype]]](output_tensor.ptr),
                    input_size,
                    owning=False,
                ),
                0,  # ì´ˆê¸°í™” ê°’ (0ìœ¼ë¡œ ì„¤ì •)
            )

            # ê¸°ì¡´ GPU ì»¤ë„ì˜ ì¬ì‚¬ìš©
            # ì´ì „: ì»¤ë„ì„ ì§ì ‘ í˜¸ì¶œ
            # í˜„ì¬: MAX Graph ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ê¸°ì¡´ ì»¤ë„ ì¬ì‚¬ìš©
            #
            # enqueue_functionì˜ ì—­í• :
            # 1. GPU ì»¤ë„ì„ ë¹„ë™ê¸° ì‹¤í–‰ íì— ì¶”ê°€
            # 2. ì»´íŒŒì¼ íƒ€ì„ ë§¤ê°œë³€ìˆ˜ ì „ë‹¬ ([...] ë¶€ë¶„)
            # 3. ëŸ°íƒ€ì„ ì¸ì ì „ë‹¬ (í…ì„œë“¤)
            # 4. ê·¸ë¦¬ë“œ/ë¸”ë¡ ì°¨ì› ì„¤ì •
            #
            # ì´ í˜¸ì¶œì´ Puzzle 11ê³¼ ë‹¤ë¥¸ ì :
            # - DeviceContextê°€ MAX Graphì—ì„œ ê´€ë¦¬ë¨
            # - í…ì„œê°€ MAX Graphì—ì„œ ì œê³µë¨
            # - ë©”ëª¨ë¦¬ ìƒëª…ì£¼ê¸°ê°€ MAX Graphì—ì„œ ê´€ë¦¬ë¨
            gpu_ctx.enqueue_function[
                conv1d_kernel[
                    in_layout,
                    output_layout,
                    conv_layout,
                    input_size,
                    conv_size,
                ]
            ](
                output_tensor,
                input_tensor,
                kernel_tensor,
                grid_dim=BLOCKS_PER_GRID,
                block_dim=(TPB, 1),
            )

        elif target == "cpu":
            # CPU í´ë°± êµ¬í˜„
            # ì´ì „: GPUë§Œ ì§€ì›
            # í˜„ì¬: CPU/GPU í•˜ì´ë¸Œë¦¬ë“œ ì§€ì›
            #
            # CPU í´ë°±ì˜ ì¤‘ìš”ì„±:
            # 1. ê°œë°œ í™˜ê²½ì—ì„œ GPUê°€ ì—†ì„ ë•Œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
            # 2. ì‘ì€ ë°ì´í„°ì—ì„œëŠ” CPUê°€ ë” íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ
            # 3. ë””ë²„ê¹… ì‹œ CPUì—ì„œ ë‹¨ê³„ë³„ ì‹¤í–‰ ê°€ëŠ¥
            # 4. í”„ë¡œë•ì…˜ í™˜ê²½ì˜ ê°€ìš©ì„± í–¥ìƒ
            #
            # í˜„ì¬ëŠ” êµ¬í˜„ë˜ì§€ ì•Šì•˜ì§€ë§Œ, ì—¬ê¸°ì— CPU ë²„ì „ì˜ ì»¨ë³¼ë£¨ì…˜ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # ì˜ˆ: NumPy ìŠ¤íƒ€ì¼ì˜ ìˆœì°¨ ì²˜ë¦¬ ë˜ëŠ” SIMD ìµœì í™”ëœ CPU ì½”ë“œ
            pass
        else:
            # ëŸ°íƒ€ì„ ì—ëŸ¬ ì²˜ë¦¬
            # ì´ì „: ì»´íŒŒì¼ íƒ€ì„ì— ëª¨ë“  ê²½ë¡œê°€ ê²°ì •ë¨
            # í˜„ì¬: ëŸ°íƒ€ì„ì— ì˜ëª»ëœ ëŒ€ìƒì´ ì „ë‹¬ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—ëŸ¬ ì²˜ë¦¬ í•„ìš”
            #
            # raises í‚¤ì›Œë“œì˜ ì¤‘ìš”ì„±:
            # 1. í•¨ìˆ˜ê°€ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¬ ìˆ˜ ìˆìŒì„ ëª…ì‹œ
            # 2. í˜¸ì¶œìì—ê²Œ ì—ëŸ¬ ì²˜ë¦¬ ì±…ì„ ì „ê°€
            # 3. MAX Graph ì‹œìŠ¤í…œì˜ ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ê³¼ í†µí•©
            raise Error("Unsupported target: " + target)


# ANCHOR_END: conv1d_custom_op

# 1. **ì‚¬ìš©ì ì •ì˜ ì—°ì‚° ë“±ë¡**: @compiler.registerë¡œ Mojo í•¨ìˆ˜ë¥¼ MAX Graphì— ë…¸ì¶œ
# 2. **Python-Mojo ë¸Œë¦¬ì§€**: InputTensor/OutputTensorë¥¼ í†µí•œ ì•ˆì „í•œ ë°ì´í„° êµí™˜
# 3. **ì»´íŒŒì¼ íƒ€ì„ ìµœì í™”**: @parameter ifë¡œ ë””ë°”ì´ìŠ¤ë³„ ì½”ë“œ ìƒì„±
# 4. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: DeviceBufferì™€ ëª…ì‹œì  ì´ˆê¸°í™”ë¥¼ í†µí•œ ì•ˆì „ì„± ë³´ì¥
# 5. **ì—ëŸ¬ ì²˜ë¦¬**: raises í‚¤ì›Œë“œë¥¼ í†µí•œ ëŸ°íƒ€ì„ ì—ëŸ¬ ì „íŒŒ
# 6. **ì½”ë“œ ì¬ì‚¬ìš©**: ê¸°ì¡´ GPU ì»¤ë„ì„ MAX Graph í™˜ê²½ì—ì„œ ì¬í™œìš©
#
# ğŸ”— ì „ì²´ ì›Œí¬í”Œë¡œìš°:
# Python (p15.py) â†’ MAX Graph â†’ @compiler.register â†’ Conv1DCustomOp.execute â†’ conv1d_kernel
#
# ì´ êµ¬ì¡°ëŠ” ì‹¤ì œ í”„ë¡œë•ì…˜ ML ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•˜ëŠ” íŒ¨í„´ìœ¼ë¡œ:
# - ì—°êµ¬ìëŠ” Pythonì—ì„œ í¸ë¦¬í•˜ê²Œ ê°œë°œ
# - ì—”ì§€ë‹ˆì–´ëŠ” Mojoë¡œ ê³ ì„±ëŠ¥ ì»¤ë„ êµ¬í˜„
# - MAX Graphê°€ ë‘˜ ì‚¬ì´ì˜ ë¸Œë¦¬ì§€ ì—­í• 
# - ìµœì¢… ì‚¬ìš©ìëŠ” ì„±ëŠ¥ê³¼ í¸ì˜ì„±ì„ ëª¨ë‘ í™•ë³´
